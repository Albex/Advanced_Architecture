\documentclass[fleqn,11pt]{SelfArx} % Document font size and equations flushed left

\setlength{\columnsep}{0.55cm} % Distance between the two columns of text
\setlength{\fboxrule}{0.75pt} % Width of the border around the abstract

\definecolor{color1}{RGB}{0,0,90} % Color of the article title and sections
\definecolor{color2}{RGB}{0,20,20} % Color of the boxes behind the abstract and headings

\newlength{\tocsep} 
\setlength\tocsep{1.5pc} % Sets the indentation of the sections in the table of contents
\setcounter{tocdepth}{3} % Show only three levels in the table of contents section: sections, subsections and subsubsections

%----------------------------------------------------------------------------------------
%	ARTICLE INFORMATION
%----------------------------------------------------------------------------------------

\JournalInfo{\ } % Journal information
\Archive{\ } % Additional notes (e.g. copyright, DOI, review/research article)

\PaperTitle{Advanced Computer Architecture: The ``Smooth'' Challenge} % Article title

\Authors{Romain Brault\textsuperscript{1}, Alexandre Camus\textsuperscript{2},  Giorgos Flourentzos\textsuperscript{3}} % Authors

\affiliation{\textsuperscript{1}RB812 \hfill \textsuperscript{2}AC5612 \hfill \textsuperscript{3}GF210}

\Keywords{} % Keywords - if you don't want any simply remove all the text between the curly brackets
\newcommand{\keywordname}{} % Defines the keywords heading name

%----------------------------------------------------------------------------------------
%	USEFULL TOOLS
%----------------------------------------------------------------------------------------

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}

\usepackage[english]{babel}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}

\theoremstyle{definition}
\newtheorem{theorem}{Theorem}

\usepackage{enumerate}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{listings}
\usepackage[pdftex=true,hyperindex=true,colorlinks=false,hidelinks]{hyperref}

\usepackage{tabularx}
\usepackage[lined,boxed,commentsnumbered]{algorithm2e}

\usepackage{placeins}

% Fonts packages (if needed)
%\usepackage[nott,fullsumlimits]{kpfonts}
%\usepackage{lmodern}
\renewcommand{\ttdefault}{txtt}

\usepackage{cite}

%----------------------------------------------------------------------------------------
%	ABSTRACT
%----------------------------------------------------------------------------------------

\Abstract{Coding is a question of how to compute things, but also how to compute them the fastest. These are often two questions that can't be resolved at once. Although coding a program that gives the expected result is an obstacle, another problem arises when performance is to be maximized. Once this is done, optimizing the written code might take a lot of time, depending on whether the hardware on which it is running, is taken into account. Here, given a correct program, the aim was to optimize it, given a chosen architecture. This consisted of understanding the code, then optimizing it sequentially and finally trying to improve it by parallelizing through vectorization or offloading the calculation to an accelerator (GPU).}

% ---------------------------------------------------------------------------------------

\begin{document}


%----------------------------------------------------------------------------------------
%	LISTINGS OPTIONS
%----------------------------------------------------------------------------------------

\lstset{
basicstyle=\ttfamily,
keywordstyle=\color{blue},
identifierstyle=,
commentstyle=\color[rgb]{.2,.4,.5},
stringstyle=\ttfamily\color{gray},
breaklines=true,
language=c++}

%----------------------------------------------------------------------------------------

\flushbottom % Makes all text pages the same height

\maketitle % Print the title and abstract box

\tableofcontents % Print the contents section

\thispagestyle{empty} % Removes page numbering from the first page

%----------------------------------------------------------------------------------------

\section{Introduction}
\subsection{Context and Objectives}

Simulation in computer science is usually computationally intensive. Although an algorithm can be theoretically efficient\footnote{With a low complexity.}, a naive implementation, without any hardware consideration reveal to be slower than expected.

This paper start with a basic implementation of a curve smoothing algorithm where the curve -- a mesh -- is represented by a graph. This paper present a various methods to reduce the computation time of the smoothing algorithm on a specific machine, according to the hardware specification. The list of optimizations presented is non exhaustive, however the considered approach reduced the computation time by approximately 1300\% on the given architecture.

The method used to achieved this speed-up is the following:
\begin{itemize}  \vspace{-4mm}
\item first optimize on one CPU core, \vspace{-4mm}
\item then parallelize over one node (here a single computer), \vspace{-4mm}
\item eventually used hardware accelerator such as GPU.
\end{itemize}

\subsection{Software Considerations}

The hardware considered is one of the Imperial College computing laboratory. All these computer are equipped with an Intel CPU, thus the best performances were obtained using the Intel Compiler\footnote{The speed-up gained by switching from g++ (GNU) to icpc (Intel) is presented section \ref{}.}. However the Imperial College computer do not have the latest version of the Intel Compiler installed on, providing some optimizations and and the use of the new C++ standard (C++11). To obtained the maximum throughput additional library, not installed on Imperial College computer, such as blitz++, were used. A solution to have the best of the latest compiler version, library flexibility and the performances of the Imperial College computers is to cross-compile the code.

Cross-compiling is the action of creating executable code for a platform other than the one on which the compiler is running. This is challenging because the compiler usually tune the code to be as fast as possible on the machine where the code is compiled lowering the performances on the target machine. Additionally, extra care must be payed to the portability of the code.

The code was compiled on a Linux-Fedora 18 64bits station and is to run on a Linux-Ubuntu 12.04 64bits station.


\FloatBarrier
\subsection{Hardware Considerations}

Table \ref{CPUspecC} and \ref{CPUspecR} show respectively the hardware characteristics of the compiling machine and the running machine. The compiling machine is much slower than the running machine but is able to generate code optimized for the running machine.

\begin{table}[!h]
	\centering

	\begin{tabularx}{0.477\textwidth}{|m{3.5cm}|>{\raggedleft\arraybackslash}m{4cm}|}
		\hline
		Model Name & Intel Core i7-QM720 \\
		\hline
		Clock Speed & 1.6 GHz \\
		\hline
		Max Turbo Frequency & 2.8 GHz \\
		\hline
		Cache line size and alignment & 64 B \\
		\hline
		CPU cores & 4 \\
		\hline
		CPU Threads & 8 \\
		\hline
		Integrated GPU & No \\
		\hline
		Memory Channels & 2 \\
		\hline
		Max Memory Bandwith & 21 GB/s \\
		\hline
		Flags & fpu, sse, sse2, sse3, ssse3, sse4\_1, sse4\_2 \\
		\hline
	\end{tabularx}

	\caption{CPU Specifications for the compiling station.}
	\label{CPUspecC}
\end{table}

\begin{table}[!h]
	\centering

	\begin{tabularx}{0.477\textwidth}{|m{3.5cm}|>{\raggedleft\arraybackslash}m{4cm}|}
		\hline
		Model Name & Intel Core i7-2600 \\
		\hline
		Clock Speed & 3.4 GHz \\
		\hline
		Max Turbo Frequency & 3.8 GHz \\
		\hline
		Cache line size and alignment & 64 B \\
		\hline
		CPU cores & 4 \\
		\hline
		CPU Threads & 8 \\
		\hline
		Integrated GPU & Intel HD Graphics 2000 \\
		\hline
		Memory Channels & 2 \\
		\hline
		Max Memory Bandwith & 21 GB/s \\
		\hline
		Flags & fpu, sse, sse2, sse3, ssse3, sse4\_1, sse4\_2, avx \\
		\hline
	\end{tabularx}

	\caption{CPU Specifications for the running station.}
	\label{CPUspecR}
\end{table}

\paragraph{}

Figure \ref{topoR} and \ref{topoC} gives the hardware topology of the compile machine the run machine. Both used an intel i7 on one socket with almost the same topology; the only difference being the size of the L3 cache of 8M on the running machine compared to 6M on the compile machine. The other main advantage of the Imperial College computer over the laptop is presence of AVX instructions. Therefore all the optimizations to tune the code on the laptop should be efficient on the Imperial College computer, except that the laptop should generate an AVX code. As a result the code could not run on the laptop which has generated the code, but will be more efficient on the Imperial College computer.

\begin{figure}
	\centering

	\includegraphics[width=.48\textwidth]{run.pdf}

	\caption{Topology of the running station.}
	\label{topoR}
\end{figure}

\begin{figure}
	\centering

	\includegraphics[width=.48\textwidth]{compile.pdf}

	\caption{Topology of the compiling station.}
	\label{topoC}
\end{figure}


%----------------------------------------------------------------------------------------
\FloatBarrier
\section{The Sequential Issue}
First the code was compiled with the g++ compiler optimised at level 3, and analyzed with Intel VTunes profiler to identify the bottlenecks. The initial speed for was $6.91$ the small size graph, $54.0$s for the medium and $510$s for the large one. It appears that the initial program spend about 80\% of its time in the function \verb+mesh_quality()+.


After running for the first time the program, it appears that the method \verb+mesh_quality()+ is the most called and so is the most expensive in computation time. Hence its code has been considered as a potential source of optimization.

Reading the code, some sequential issues were found. There are three kinds of problems: the algorithms chosen, the coding style and the data's representation.

\subsection{Algorithm}

The method used to solve an equations' system was correct but two general to be efficient. The program needs only to solve systems of two equations in two unknowns. The Cramer's rule based on determinants is far more efficient. The Cramer's rule is as following:

\begin{theorem}
\hrule \vspace*{1pt}
Given an equations system $Ax = b$, where $A$ is a squared matrix of size $n$, and $x$ and $b$ two $n$-vertical vectors.

If $\det A \neq 0$ then the system has exactly one solution. Its solution is:
\[x_i = \dfrac{\det A_i}{\det A}\]
where $x = (x_1,\dots,x_i)^T$ and $A_i$ is the matrix formed by replacing the $i$-th column of $A$  by the column vector $b$. 

In this case ($2\times2$), the result is:
\begin{align*}
x_1 &= \dfrac{(b_1 \times a_{2,2}) - (b_2 \times a_{1,2})}{(a_{1,1} \times a_{2,2}) - (a_{2,1} \times a_{1,2})} \\
x_2 &= \dfrac{(a_{1,1} \times b_2) - (a_{2,1} \times b_1)}{(a_{1,1} \times a_{2,2}) - (a_{2,1} \times a_{1,2})}
\end{align*}
\hrule
\end{theorem}

The use of the method \verb+pow()+ seems a little too heavy in the method \verb+element_quality()+. As the number of multiplication is known, the use of simple multiplications is more efficient here, e.g. \verb+x*x*x+.

\subsection{Code Style}

Few changes in the style of the code might help the compiler. Some of these changes have been done to speed up the program.

First of all, the code has been slightly rewritten in order to be more oriented object than before. Basically all the attributes of the \verb+Mesh+ class have been set to private and the \verb+smooth+ function is now a method of this class. This did not really increase the performance. But this was for a better readability. It might also help the compiler to improve its compiled code as it is used to read object oriented code. 

Inline functions do often help the compiler to optimize the translated assembly language. That is why functions like \verb+isSurfaceNode()+ or \verb+isCornerNode()+ or \verb+element_quality()+ or \verb+svd_solve_2x2()+.

In loops changes have been made to avoid recomputation of the invariant (e.g. calling \verb+.size()+ in a loop). Instead, this invariant is now stored in a local variable.

\subsection{Data's Representation}

The data structure used is fine and one of the most efficient to represent a graph. However, the C++ structures used seem to be a little too big in this case. So instead of using vectors of sets, the program is now using vectors of vectors. This increases a little the global performance.

Similarly, the number of node does not exceed $10^5$ which is less than the maximum integer represented thanks to the \verb+uint32_t+. This type is faster to manipulate than the classic \verb+int+ type. Hence \verb+uint32_t+ has been preferred.

In the \verb+element_quality()+ method, the call of an element in a matrix during its multiplication, is very expensive in memory access. So instead of calling the element at each step of the loop, it is better to use an intermediate variable that is assigned into the matrix element at the end.

Finally the vectors \verb+normals+ and \verb+ENList+ are not anymore vectors. The {Blitz library}\footnote{\url{http://blitz.sourceforge.net/}} provides useful arrays' types with a speed comparable to Fortran implementations. After testing it on the different vectors in the program, it appears that the type \verb+Array+ of this library was more efficient for vectors that are linearly accessed. \verb+normals+ and \verb+ENList+ have this property. So they are now implemented thanks to \verb+Array+ type.

%----------------------------------------------------------------------------------------

\section{CPU Parallelization}

\subsection{Analysis}

Parallelization can't be done easily. The program needs to be slightly modified in order to cut the graph in groups of independent nodes. Independent nodes are nodes that can be inspected at the same time while running the program. To group nodes in such groups the graph must be colored. Then each color represents nodes that can be inspected at the same time because they are not adjacent.

But the coloring algorithm might be very expensive in computation time. This depends on the number of colors used and if this number is specified or not. In this very case, the goal of such an algorithm is to minimize the colors used in order to maximize parallel computations. Hence a powerful algorithm is needed.

\subsection{Optimization}

A first try was realized with a very complex algorithm that colors a graph with minimum of colors needed. But the simple fact of coloring the graph was itself longer than the original program (hundreds of minutes). This confirmed that the graph is complex and parallelizing the program will surely reduce the run time.

So the coloring algorithm finally chosen was very basic. It just tries to color the graph without minimizing the number of colors used. It succeeds in coloring the graphs with 4 or 5 colors. Algorithms \ref{coloring} and \ref{getcolors} are its implementation in pseudocode.

\begin{algorithm}[h]
\SetKwData{Left}{left}\SetKwData{This}{this}\SetKwData{Up}{up}
\SetKwFunction{Union}{Union}\SetKwFunction{FindCompress}{FindCompress}
\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}

\Input{the graph $G$}
\Output{$C$ the array containing the colors}
\BlankLine

creating $C$, the output of size: number of node\;
intializing each element of $C$ to $-1$\;
\For{$i \leqslant \text{number of node}$}{
	$C[i] \leftarrow get\_colors( G[i] )$\;
}
\Return C\;

\caption{The \texttt{coloring} Algorithm}
\label{coloring}
\end{algorithm}

\begin{algorithm}[h]
\SetAlgoLined
\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}

\Input{the array $A$ of all neighbours of one node}
\Output{return the color $C$ which is not used by other neighbours}
\BlankLine

$C := 0$\;
\While{}{
	\For{$i \leqslant \text{number of neighbours}$}{
		\If{$C = A[i]$}{$C := C + 1$\; \textbf{break}\;}
	}
	\If{$i = \text{number of neighbours}$}{\Return C\;}
}

\caption{The \texttt{get\_colors} Algorithm}
\label{getcolors}
\end{algorithm}

Then each color represents a set of nodes that are computable in parallel. Actually this is simply done by adding a \verb+for+ loop on the colors before the loop that inspects all the nodes of the graph. The color of each node is compared to the current color. If they are different the node is skipped. The parallelization is then simply done on the loop that inspects all the nodes.

%----------------------------------------------------------------------------------------

\section{Results}

\subsection{Sequential Improvements}

\subsection{Parallelization Performance}

\end{document}